import os
from dotenv import load_dotenv
import asyncio
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

prompt = ChatPromptTemplate.from_template("ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯")
model = ChatOpenAI(
    model='deepseek-chat',
    max_tokens=1024,
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url=os.getenv("DEEPSEEK_BASE_URL")
)
parser = StrOutputParser()
chain = prompt | model | parser


async def async_stream():
    async for chunk in chain.astream({"topic": "å·¥ä½œ"}):
        print(chunk, end="|", flush=True)

# è¿è¡Œå¼‚æ­¥æµå¤„ç†
asyncio.run(async_stream())
'''
|å¥½çš„|ï¼|è¿™æ˜¯ä¸€ä¸ª|å…³äº|å·¥ä½œçš„|ç»å…¸|ç¬‘è¯|ï¼š

|---

|**|è€æ¿|**|ï¼š|æˆ‘ä»¬|å…¬å¸|å´‡å°š|å¹³ç­‰|ï¼Œ|åœ¨è¿™é‡Œ|æ²¡æœ‰|ç­‰çº§|è§‚å¿µ|ï¼|  
|**|æ–°|å‘˜å·¥|**|ï¼š|å¤ªå¥½äº†|ï¼|é‚£|æˆ‘å¯ä»¥|ç›´æ¥|å«|æ‚¨|åå­—|å—|ï¼Ÿ|  
|**|è€æ¿|**|ï¼š|å½“ç„¶|å¯ä»¥|ã€‚|  
|**|æ–°|å‘˜å·¥|**|ï¼š|å¥½çš„|ï¼Œ|è€ç‹|ã€‚|  
|**|è€æ¿|**|ï¼š|â€¦â€¦|å«æˆ‘|ç‹|æ€»|ã€‚|  

|ï¼ˆ|å†·ç¬‘|è¯|Bonus|ï¼š|å¹³ç­‰|çš„å‰æ|æ˜¯|â€œ|æ€»|â€|å¾—|æœ‰äºº|åŠ ç­|ã€‚ï¼‰|  

|---|

|å¸Œæœ›|è®©ä½ |ä¼š|å¿ƒ|ä¸€ç¬‘|ï½| ğŸ˜„||
'''